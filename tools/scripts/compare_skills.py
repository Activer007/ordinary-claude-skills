#!/usr/bin/env python3
"""
æŠ€èƒ½å¯¹æ¯”åˆ†æè„šæœ¬
å¯¹æ¯”å¤šä¸ªæŠ€èƒ½çš„è¯„åˆ†ç»†èŠ‚ï¼Œè¯†åˆ«é‡å¤æŠ€èƒ½
"""

import sys
from pathlib import Path
from difflib import SequenceMatcher

# æ·»åŠ çˆ¶ç›®å½•åˆ° Python è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent))

from analyzer.skill_analyzer import SkillAnalyzer
from analyzer import utils


def calculate_similarity(str1: str, str2: str) -> float:
    """
    è®¡ç®—ä¸¤ä¸ªå­—ç¬¦ä¸²çš„ç›¸ä¼¼åº¦

    Args:
        str1: å­—ç¬¦ä¸²1
        str2: å­—ç¬¦ä¸²2

    Returns:
        ç›¸ä¼¼åº¦ï¼ˆ0.0-1.0ï¼‰
    """
    return SequenceMatcher(None, str1.lower(), str2.lower()).ratio()


def print_comparison_table(results: list):
    """
    æ‰“å°å¯¹æ¯”è¡¨æ ¼

    Args:
        results: åˆ†æç»“æœåˆ—è¡¨
    """
    print("\n" + "=" * 100)
    print("ğŸ“Š Skills å¯¹æ¯”åˆ†ææŠ¥å‘Š")
    print("=" * 100 + "\n")

    # è¡¨å¤´
    print(f"{'Skill Name':<30} {'Total':<8} {'Grade':<8} {'Content':<10} {'Technical':<10} {'Maint':<8} {'UX':<6}")
    print("-" * 100)

    # å„ä¸ªæŠ€èƒ½çš„è¯„åˆ†
    for result in results:
        if 'error' in result:
            name = result['skill_name']
            print(f"{name:<30} {'ERROR':<8} {'-':<8} {'-':<10} {'-':<10} {'-':<8} {'-':<6}")
        else:
            name = result['skill_name']
            total = result['total_score']
            grade = result['grade']

            scores = result['scores']
            content = f"{scores['content']['total']}/50"
            technical = f"{scores['technical']['total']}/30"
            maintenance = f"{scores['maintenance']['total']}/10"
            ux = f"{scores['ux']['total']}/10"

            print(f"{name:<30} {total:<8} {grade:<8} {content:<10} {technical:<10} {maintenance:<8} {ux:<6}")

    print("=" * 100 + "\n")


def print_similarity_analysis(skill_names: list):
    """
    æ‰“å°åç§°ç›¸ä¼¼åº¦åˆ†æ

    Args:
        skill_names: æŠ€èƒ½åç§°åˆ—è¡¨
    """
    if len(skill_names) < 2:
        return

    print("ğŸ” åç§°ç›¸ä¼¼åº¦åˆ†æ\n")

    for i in range(len(skill_names)):
        for j in range(i + 1, len(skill_names)):
            similarity = calculate_similarity(skill_names[i], skill_names[j])

            if similarity > 0.5:  # ç›¸ä¼¼åº¦è¶…è¿‡ 50%
                print(f"  {skill_names[i]} <-> {skill_names[j]}: {similarity*100:.1f}%")

                if similarity > 0.8:
                    print(f"    âš ï¸  é«˜åº¦ç›¸ä¼¼ï¼Œå¯èƒ½æ˜¯é‡å¤æŠ€èƒ½")

    print()


def print_recommendations(results: list):
    """
    æ‰“å°æ¨èå»ºè®®

    Args:
        results: åˆ†æç»“æœåˆ—è¡¨
    """
    valid_results = [r for r in results if 'error' not in r]

    if not valid_results:
        return

    # æ‰¾å‡ºæœ€ä½³æŠ€èƒ½
    best = max(valid_results, key=lambda x: x['total_score'])

    print("ğŸ’¡ æ¨èå»ºè®®\n")
    print(f"  ğŸ“Œ æ¨èä½¿ç”¨: {best['skill_name']} ({best['total_score']}åˆ†, {best['grade']}çº§)")

    # åˆ†æå·®å¼‚
    if len(valid_results) > 1:
        worst = min(valid_results, key=lambda x: x['total_score'])

        if best != worst:
            score_diff = best['total_score'] - worst['total_score']
            print(f"  ğŸ“Š æœ€å¤§åˆ†å·®: {score_diff}åˆ†")

            # åˆ†æä¼˜åŠ¿
            best_scores = best['scores']
            worst_scores = worst['scores']

            print(f"\n  {best['skill_name']} çš„ä¼˜åŠ¿:")

            if best_scores['content']['total'] > worst_scores['content']['total']:
                diff = best_scores['content']['total'] - worst_scores['content']['total']
                print(f"    â€¢ å†…å®¹è´¨é‡é«˜ {diff}åˆ†")

            if best_scores['technical']['total'] > worst_scores['technical']['total']:
                diff = best_scores['technical']['total'] - worst_scores['technical']['total']
                print(f"    â€¢ æŠ€æœ¯å®ç°å¥½ {diff}åˆ†")

    print()


def main():
    """ä¸»å‡½æ•°"""
    if len(sys.argv) < 3:
        print("Usage: python compare_skills.py <skill1> <skill2> [skill3] ...")
        print("\nExample:")
        print("  python compare_skills.py pdf pdf-processing pdf-processing-pro")
        print("\nNote: Skill names will be searched in ../skills_all/")
        sys.exit(1)

    skill_names = sys.argv[1:]

    if len(skill_names) > 5:
        print("âŒ Error: Maximum 5 skills can be compared at once")
        sys.exit(1)

    # æŠ€èƒ½ç›®å½•
    skills_dir = Path(__file__).parent.parent.parent / 'skills_all'

    if not skills_dir.exists():
        print(f"âŒ Error: Skills directory not found: {skills_dir}")
        sys.exit(1)

    # åŠ è½½é…ç½®
    config_path = Path(__file__).parent.parent / 'config' / 'scoring_weights.json'
    config = utils.load_config(config_path)

    # åˆ†ææ¯ä¸ªæŠ€èƒ½
    results = []

    print(f"\nğŸ” Comparing {len(skill_names)} skills...\n")

    for skill_name in skill_names:
        skill_path = skills_dir / skill_name

        if not skill_path.exists():
            print(f"  âœ— {skill_name}: Not found")
            results.append({
                'skill_name': skill_name,
                'error': 'Skill not found',
                'total_score': 0,
                'grade': 'ERROR',
            })
            continue

        print(f"  âœ“ {skill_name}: Analyzing...", end='')

        try:
            analyzer = SkillAnalyzer(skill_path, config)
            result = analyzer.analyze()
            results.append(result)

            if 'error' not in result:
                print(f" Done ({result['total_score']} points)")
            else:
                print(f" Error: {result['error']}")

        except Exception as e:
            print(f" Exception: {str(e)}")
            results.append({
                'skill_name': skill_name,
                'error': str(e),
                'total_score': 0,
                'grade': 'ERROR',
            })

    # æ‰“å°å¯¹æ¯”è¡¨æ ¼
    print_comparison_table(results)

    # æ‰“å°ç›¸ä¼¼åº¦åˆ†æ
    print_similarity_analysis(skill_names)

    # æ‰“å°æ¨èå»ºè®®
    print_recommendations(results)


if __name__ == '__main__':
    main()
